{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TypicalCase_ConvectiveCellTracking_20170413.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQaN-IT3IF8s",
        "colab_type": "text"
      },
      "source": [
        "#Convective Cell Identification & TRAcking (CITRA) using Doppler Weather Radar Images\n",
        "\n",
        "The cell below installs the Tesseract-OCR model and the Google Drive Mount sequence.\n",
        "\n",
        "**NOTE**: - When the below cell in run, it pops up a link to request access to your google drive. Open that link and grant acces. Then copy the access code and paste it in the mentioned area in the installation sequence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-zj_4gCIZ4c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pytesseract\n",
        "!sudo apt install tesseract-ocr\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMiKf_1OH-si",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"Mesoscale Convective System Identification and Tracking using Doppler Weather Radar Images\"\"\"\n",
        "\"\"\"by A Niranjan\"\"\"\n",
        "\n",
        "\"\"\"Algorithm for plotting the Convective_System sequence with a folder of consecutive images given as input\"\"\"\n",
        "\n",
        "#Importing the necessary libraries for the project\n",
        "\n",
        "\"\"\"\n",
        "LIBRARY : USE\n",
        "\n",
        "1. cv2: OpenSourced Computer Vision Library for image recognition.\n",
        "2. Numpy: Popular Numerical Python library for various matrix calculations.\n",
        "3. time: Simulation time analysis.\n",
        "4. os: OS file handling.\n",
        "5. pytesseract: An opensource text recognition library for image matrix to string conversions.\n",
        "6. imutils: Image Utilities for basic image processing functions.\n",
        "7. contours: Potential area boundary formations.\n",
        "8. skimage: OpenSource Measure analysis and image recognition Library for segmentation, geometric transformations and color space manipulation.\n",
        "9. argparse: For passing arguments to the algorithm from terminal.\n",
        "10. scipy.spatial: Displacement analysis.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import time,os\n",
        "import pytesseract\n",
        "import imutils \n",
        "from imutils import contours\n",
        "from skimage import measure\n",
        "import argparse\n",
        "from scipy.spatial import distance\n",
        "import glob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvP6qdgFIf6H",
        "colab_type": "text"
      },
      "source": [
        "##os.chdir('Your_Data_path_from_Google_Drive')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXD5glF9IcVt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Setting the working directory\n",
        "os.chdir('/content')\n",
        "\n",
        "#Setting the path to the tesseract library executable file\n",
        "pytesseract.pytesseract.tesseract_cmd = (\n",
        "    r'/usr/bin/tesseract'\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqy7ko0_IcSX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function for Contour formation with respect to Single Strength bar images.\n",
        "def formcontour_Single1(x):\n",
        "    \n",
        "    #Initializing Time sequence \n",
        "    start = time.time()\n",
        "\n",
        "    #Decleration of global variables for image-1 perspective analysis in later functions\n",
        "    global dresolution_1, Date_1, Time_1, Area_1, cX1, cY1, approx1\n",
        "    img_main = x\n",
        "\n",
        "    #Cropping the image with respect to Radar Field in the image\n",
        "#     img_radar = x[43:752,6:759]\n",
        "    img_radar = x[183:755,4:600]\n",
        "    #Convertion of the image into Gray scale and then a blur filter is used to patch the image \n",
        "    gray = cv.cvtColor(img_radar, cv.COLOR_BGR2GRAY)\n",
        "    blurred = cv.GaussianBlur(gray, (11, 11), 0)\n",
        "\n",
        "    #Thresholding the image for potential area identification\n",
        "    thresh = cv.threshold(blurred, 200, 255, cv.THRESH_BINARY)[1]\n",
        "    thresh = cv.erode(thresh, None, iterations=1)\n",
        "    thresh = cv.dilate(thresh, None, iterations=1)\n",
        "\n",
        "    #Connected Component Analysis to find the major patch formations\n",
        "    labels = measure.label(thresh, connectivity = 2, background=0)\n",
        "    mask = np.zeros(thresh.shape, dtype=\"uint8\")\n",
        "\n",
        "    # Loop formation over the unique categories\n",
        "    for label in np.unique(labels):\n",
        "\n",
        "\n",
        "        # If it were the background label then ignore it\n",
        "        if label == 0:\n",
        "            continue\n",
        "\n",
        "        # If it were the background label then ignore it \n",
        "        labelMask = np.zeros(thresh.shape, dtype=\"uint8\")\n",
        "        labelMask[labels == label] = 255\n",
        "        numPixels = cv.countNonZero(labelMask)\n",
        "\n",
        "\n",
        "        # Adding the large components to the mask layer if the total number of connected pixels exceed the 150 range\n",
        "        if numPixels > 150:\n",
        "            mask = cv.add(mask, labelMask)\n",
        "\n",
        "\n",
        "    \"\"\"Implementation of the pytesseract library for text recognition and processing, the pytesseract library can \n",
        "    only process images in the RGB Spectrucm, so it is converted from BGR to RGB colour space\"\"\"\n",
        "\n",
        "#     Date_1 = pytesseract.image_to_string((cv.cvtColor(img_main[14:39, 3:137],cv.COLOR_BGR2RGB)))\n",
        "    Date_1 = pytesseract.image_to_string((cv.cvtColor(img_main[13:37,5:135],cv.COLOR_BGR2RGB)))\n",
        "#     Time_1 = pytesseract.image_to_string(cv.resize((cv.cvtColor(img_main[14:43, 233:333],cv.COLOR_BGR2RGB)),(150,30)))\n",
        "    Time_1 = pytesseract.image_to_string(cv.resize((cv.cvtColor(img_main[15:35,230:305],cv.COLOR_BGR2RGB)),(150,30)))\n",
        "    #In few cases the image needs to be resized for better recognition\n",
        "    #Lattitude and Logitude detection\n",
        "    lat = pytesseract.image_to_string((cv.resize((cv.cvtColor((img_main[20:39,794:848]),cv.COLOR_BGR2RGB)),(69,25))))\n",
        "    long = pytesseract.image_to_string((cv.resize((cv.cvtColor((img_main[22:39,863:925]),cv.COLOR_BGR2RGB)),(310,75))))\n",
        "\n",
        "    #Kilometer per pixel area recognition.\n",
        "#     dresolution_1 =float(pytesseract.image_to_string(cv.resize(((cv.cvtColor((image1[83:100,923:960]),cv.COLOR_BGR2RGB))),(150,70))))\n",
        "    dresolution_1 = 0.8\n",
        "    #Potential area contour formation for displaying the largest patches of the anomaly\n",
        "    _, contours, _=cv.findContours(mask,cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    #Storing all the contour areas in one list\n",
        "    cntArea = [cv.contourArea(c) for c in contours]\n",
        "    for cnt in contours:\n",
        "\n",
        "        #Only the largest contour area is considered for plotting\n",
        "        if(cv.contourArea(cnt) == max(cntArea)):\n",
        "            epsilon = 0.01*cv.arcLength(cnt,True)\n",
        "\n",
        "            #Polygonal Structure approximation\n",
        "            approx1 = cv.approxPolyDP(cnt,epsilon,True)\n",
        "\n",
        "            #Drawing the contour\n",
        "            cv.drawContours(img_radar,[approx1],0,(0,0,255),2)\n",
        "\n",
        "            #Total number of pixels enclosed by the contour\n",
        "            TotalPixels = cv.contourArea(cnt)\n",
        "\n",
        "            #Area Calculation with respect to the km/pixel value as the image is in a (xx,xx,3) format the values measured are \n",
        "            #divided with 30 as the colour spectrum of 3 layers is calculated with respect to kilometer squares.\n",
        "            Area_1 = ((TotalPixels/30)*dresolution_1)\n",
        "\n",
        "            #Determining the centroid of the countour\n",
        "            X = cv.moments(cnt)\n",
        "            cX1 = int(X[\"m10\"] / X[\"m00\"])\n",
        "            cY1 = int(X[\"m01\"] / X[\"m00\"])\n",
        "\n",
        "            #Drawing a line perpendicular from the RADAR to the Contour centroid\n",
        "            cv.line(img_radar, (int(299), int(288)), (int(cX1), int(cY1)),(0,255,0), 2)\n",
        "\n",
        "            #Drwing points on the Contour Centroid and the RADAR Origin\n",
        "            cv.circle(img_radar, (cX1, cY1), 3, (0, 0, 0), -5)\n",
        "#             cv.circle(img_radar, (376,353),3,(0,0,0),-5)\n",
        "            cv.circle(img_radar, (299,288),3,(0,0,0),-5)\n",
        "            \n",
        "            #Calculating the distance between the Contour Centroid and the RADAR Origin\n",
        "            D = distance.euclidean((363,329),(cX1,cY1))\n",
        "            DistanceFromRadar = round(D,2)\n",
        "\n",
        "\n",
        "            #Printing all the necessary details         \n",
        "#             print('RADAR 1:') \n",
        "#             print('Date1: '+ Date_1)\n",
        "#             print('Time Stamp 1: ' + Time_1)\n",
        "#             print('Radar Lat&Long: '+lat+\" , \"+long)\n",
        "#             print('Distance From Radar:',round(DistanceFromRadar*dresolution_1,2), 'km',DirectionOfAnomaly(cX1,cY1))        \n",
        "#             print(\"Total Area Covered is: \"+str(round(Area_1,2))+\" Km.sq\")\n",
        "\n",
        "#             #Ending the time sequence\n",
        "#             end = time.time()\n",
        "#             print(f\"Runtime {end - start}\")\n",
        "            \n",
        "#             cv.imwrite(r'C:\\Users\\niran\\Desktop\\Radar_Image_Processing\\RadarData\\GIF_Images\\2017\\April\\13th\\TwoImages\\ConvectiveSystem1.jpeg',img_radar)\n",
        "            \n",
        "#             #Displaying the image\n",
        "#             cv.imshow(\"Result 1\",img_radar)\n",
        "            return 'Successful'\n",
        "\n",
        "def getRadarStats_Single1(x):\n",
        "    ContourFormation = formcontour_Single1(x)\n",
        "    if(ContourFormation == 'Successful'):\n",
        "        return 'Successful'\n",
        "    else: print('No Anomaly in 1st Image\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVUacOukIcQD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function for Contour formation with respect to Single Strength bar images.\n",
        "def formcontour_Single2(x):\n",
        "    #Initializing Time sequence\n",
        "    start = time.time()\n",
        "    \n",
        "    #Decleration of global variables for image-1 perspective analysis in later functions\n",
        "    global dresolution_2, Date_2, Time_2, Area_2, cX2, cY2, img_radar2\n",
        "    img_main = x\n",
        "    \n",
        "    #Decleration of global variables for image-1 perspective analysis in later functions\n",
        "#     img_radar2 = x[43:752,6:759]\n",
        "    img_radar2 = x[183:755,4:600]\n",
        "    #Convertion of the image into Gray scale and then a blur filter is used to patch the image \n",
        "    gray = cv.cvtColor(img_radar2, cv.COLOR_BGR2GRAY)\n",
        "    blurred = cv.GaussianBlur(gray, (11, 11), 0)\n",
        "    \n",
        "    #Thresholding the image for potential area identification\n",
        "    thresh = cv.threshold(blurred, 200, 255, cv.THRESH_BINARY)[1]\n",
        "    thresh = cv.erode(thresh, None, iterations=1)\n",
        "    thresh = cv.dilate(thresh, None, iterations=1)\n",
        "    \n",
        "    #Connected Component Analysis to find the major patch formations\n",
        "    labels = measure.label(thresh, connectivity = 2, background=0)\n",
        "    mask = np.zeros(thresh.shape, dtype=\"uint8\")\n",
        "\n",
        "    # Loop formation over the unique categories\n",
        "    for label in np.unique(labels):\n",
        "        \n",
        "        # If it were the background label then ignore it\n",
        "        if label == 0:\n",
        "            continue\n",
        "\n",
        "        \n",
        "        # Construction of the label mask and determining the total number of pixels in the patches\n",
        "        labelMask = np.zeros(thresh.shape, dtype=\"uint8\")\n",
        "        labelMask[labels == label] = 255\n",
        "        numPixels = cv.countNonZero(labelMask)\n",
        "\n",
        "\n",
        "\n",
        "        # Adding the large components to the mask layer if the total number of connected pixels exceed the 150 range\n",
        "        if numPixels > 150:\n",
        "            mask = cv.add(mask, labelMask)\n",
        "            \n",
        "    \"\"\"Implementation of the pytesseract library for text recognition and processing, the pytesseract library can \n",
        "    only process images in the RGB Spectrucm, so it is converted from BGR to RGB colour space\"\"\"\n",
        "    \n",
        "#     Date_2 = pytesseract.image_to_string((cv.cvtColor(img_main[14:39, 3:137],cv.COLOR_BGR2RGB)))\n",
        "    Date_2 = pytesseract.image_to_string((cv.cvtColor(img_main[13:37,5:135],cv.COLOR_BGR2RGB)))\n",
        "#     Time_2 = pytesseract.image_to_string(cv.resize((cv.cvtColor(img_main[14:43, 233:333],cv.COLOR_BGR2RGB)),(150,30)))\n",
        "    Time_2 = pytesseract.image_to_string(cv.resize((cv.cvtColor(img_main[15:35,230:305],cv.COLOR_BGR2RGB)),(150,30)))\n",
        "    #In few cases the image needs to be resized for better recognition\n",
        "    #Lattitude and Logitude detection\n",
        "    lat = pytesseract.image_to_string((cv.resize((cv.cvtColor((img_main[20:39,794:848]),cv.COLOR_BGR2RGB)),(69,25))))\n",
        "    long = pytesseract.image_to_string((cv.resize((cv.cvtColor((img_main[22:39,863:925]),cv.COLOR_BGR2RGB)),(310,75))))\n",
        "    \n",
        "    #Kilometer per pixel area recognition.\n",
        "#     dresolution_2 =float(pytesseract.image_to_string(cv.resize(((cv.cvtColor((image1[83:100,923:960]),cv.COLOR_BGR2RGB))),(150,70))))\n",
        "    dresolution_2 = 0.8\n",
        "    #Potential area contour formation for displaying the largest patches of the anomaly\n",
        "    _, contours, _=cv.findContours(mask,cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
        "    \n",
        "    #Storing all the contour areas in one list\n",
        "    cntArea = [cv.contourArea(c) for c in contours]\n",
        "    \n",
        "    \n",
        "    for cnt in contours:\n",
        "        \n",
        "        #Only the largest contour area is considered for plotting\n",
        "        if(cv.contourArea(cnt) == max(cntArea)):\n",
        "            epsilon = 0.01*cv.arcLength(cnt,True)\n",
        "            \n",
        "            #Polygonal Structure approximation\n",
        "            approx = cv.approxPolyDP(cnt,epsilon,True)\n",
        "            \n",
        "            #Drawing the contour\n",
        "            img_radar2 = cv.drawContours(img_radar2,[approx],0,(0,0,255),2)\n",
        "            \n",
        "            #Total number of pixels enclosed by the contour\n",
        "            TotalPixels = cv.contourArea(cnt)\n",
        "            \n",
        "            #Area Calculation with respect to the km/pixel value as the image is in a (xx,xx,3) format the values measured are \n",
        "            #divided with 30 as the colour spectrum of 3 layers is calculated with respect to kilometer squares.\n",
        "            Area_2 = ((TotalPixels/30)*dresolution_2)\n",
        "            \n",
        "            #Determining the centroid of the countour\n",
        "            X = cv.moments(cnt)\n",
        "            cX2 = int(X[\"m10\"] / X[\"m00\"])\n",
        "            cY2 = int(X[\"m01\"] / X[\"m00\"])\n",
        "            \n",
        "            #Drawing a line perpendicular from the RADAR to the Contour centroid\n",
        "            img_radar2 = cv.line(img_radar2, (int(299), int(288)), (int(cX2), int(cY2)),(0,255,0), 2)\n",
        "            \n",
        "            #Drwing points on the Contour Centroid and the RADAR Origin\n",
        "            img_radar2 = cv.circle(img_radar2, (cX2, cY2), 3, (0, 0, 0), -5)\n",
        "#             img_radar2 = cv.circle(img_radar2, (376,353),3,(0,0,0),-5)\n",
        "            img_radar2 = cv.circle(img_radar2, (299,288),3,(0,0,0),-5)\n",
        "    \n",
        "            #Calculating the distance between the Contour Centroid and the RADAR Origin\n",
        "            D = distance.euclidean((363,329),(cX2,cY2))\n",
        "            DistanceFromRadar = round(D,2)\n",
        "            \n",
        "            #Printing all the necessary details  \n",
        "#             print('RADAR 2:')\n",
        "#             print('Date2: '+ Date_2)\n",
        "#             print('Time Stamp 2: ' + Time_2)\n",
        "#             print('Radar Lat&Long: '+lat+\" , \"+long)\n",
        "#             print('Distance From Radar:',round(DistanceFromRadar*dresolution_2,2), 'km',DirectionOfAnomaly(cX2,cY2))        \n",
        "#             print(\"Total Area Covered is: \"+str(round(Area_2,2))+\" Km.sq\")\n",
        "\n",
        "#             #Ending the time sequence\n",
        "#             end = time.time()\n",
        "#             print(f\"Runtime {end - start}\")\n",
        "\n",
        "#             cv.imwrite(r'C:\\Users\\niran\\Desktop\\Radar_Image_Processing\\RadarData\\GIF_Images\\2017\\April\\13th\\TwoImages\\ConvectiveSystem2.jpeg',img_radar2)\n",
        "            \n",
        "#             #Ending the time sequence\n",
        "#             cv.imshow(\"Result 2\",img_radar2)\n",
        "            \n",
        "            return 'Successful'\n",
        "#Function for Radar statistics of Single strength bar image-2\n",
        "def getRadarStats_Single2(x):\n",
        "    ContourFormation = formcontour_Single2(x)\n",
        "    if(ContourFormation == 'Successful'): \n",
        "        return 'Successful'\n",
        "    else: print('No Anomaly in 2nd Image')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6avgxlU6IcNx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Combined function for RADAR information determination and tracking.\n",
        "#In the following function the conditional statements are used to execute various functions depending on the image dimensions.\n",
        "def FinalRadarStats(image1,image2):\n",
        "    global radar1_info, radar2_info\n",
        "    \n",
        "    if(image1.shape == (770,1078,3)):\n",
        "        radar1_info = getRadarStats_Single1(image1)\n",
        "    elif(image1.shape == (720,1082,3)):\n",
        "        radar1_info = getRadarStats_Double1(image1)\n",
        "    if(image2.shape == (770,1078,3)):\n",
        "        radar2_info = getRadarStats_Single2(image2)\n",
        "    elif(image2.shape == (720,1082,3)):\n",
        "        radar2_info = getRadarStats_Double2(image2)\n",
        "\n",
        "#Initializing the timer sequence \n",
        "start = time.time()\n",
        "\n",
        "#list to store file names \n",
        "file_names = []\n",
        "\n",
        "#List to store all the anomaly centroids\n",
        "anomaly_centroids = []\n",
        "\n",
        "#adding all the file names to the list\n",
        "for i in glob.glob('*.gif*'):\n",
        "    file_names.append(i)\n",
        "\n",
        "#Reading all the .gif images in the folder and capturing the images for image processing\n",
        "for i in range(0,len(file_names)-1):\n",
        "    gif1 = cv.VideoCapture(file_names[i])\n",
        "    ret1,image1 = gif1.read()\n",
        "    image1 = cv.resize(image1,(1078,770))\n",
        "    \n",
        "    gif2 = cv.VideoCapture(file_names[i+1])\n",
        "    ret2,image2 = gif2.read()\n",
        "    image2 = cv.resize(image2,(1078,770))\n",
        "    \n",
        "\n",
        "    \n",
        "    #Calling the main function for image processing\n",
        "    FinalRadarStats(image1,image2)\n",
        "    if(radar1_info == 'Successful' and radar2_info == 'Successful'):\n",
        "#         if(file_names[i] == file_names[0]):\n",
        "#             global initialanomaly_Time \n",
        "#             initialanomaly_Time = Time_1\n",
        "#             print('Initial Anomaly Time'+ initialanomaly_Time)\n",
        "#         if(file_names[i]==file_names[-1]):\n",
        "#             global finalanomaly_Time \n",
        "#             finalanomaly_Time = Time_2\n",
        "#             print('Final Anomaly Time'+ finalanomaly_Time)\n",
        "            \n",
        "        #Determining the time & area difference between the consecutive anomalies from the global variables declared in the functions\n",
        "        time_difference = round((abs(get_sec(Time_1)-get_sec(Time_2)))/60,2)\n",
        "        area_difference = round((abs(Area_1 - Area_2)),2)\n",
        "\n",
        "        #Displacement of the anomaly\n",
        "        distance_travelled = round(  (distance.euclidean((cX1,cY1),(cX2,cY2)))*dresolution_2 ,2)\n",
        "\n",
        "        # The following statement will run if the time difference is less than 70minutes, Area difference is less than 20 km.sq \n",
        "        # and displacement less than 100 km.sq\n",
        "        if(time_difference < 70 and area_difference < 40 and distance_travelled < 100):\n",
        "\n",
        "            #Drawing relationg between consecutive frames\n",
        "    #         img_radar2 = cv.drawContours(img_radar2,[approx1],0,(0,255,0),2)\n",
        "            img_radar2 = cv.line(img_radar2, (int(cX1), int(cY1)), (int(cX2), int(cY2)),(0,255,0), 2)\n",
        "            img_radar2 = cv.circle(img_radar2, (cX1, cY1), 3, (0, 0, 0), -5)\n",
        "            img_radar2 = cv.circle(img_radar2, (cX2, cY2), 3, (0, 0, 0), -5)\n",
        "\n",
        "\n",
        "            #Adding the centroid values to the lists\n",
        "    #       print('Coordinates1: ','[',cX1,cY1,']','\\t','Coordinates2','[',cX2,cY2,']','\\n')\n",
        "            anomaly_centroids.append([cX1,cY1])\n",
        "            anomaly_centroids.append([cX2,cY2])\n",
        "\n",
        "        else: \n",
        "            print(\"Anomaly could not be traced from \", file_names[i],'&',file_names[i+1])\n",
        "    else: \n",
        "        print('Anomaly correlation not found\\n')\n",
        "    i += 1\n",
        "\n",
        "#Declaration of the final centroid list to store only exact values which are necessary\n",
        "final_anomaly_centroids = []\n",
        "\n",
        "#Loop to remove duplicates and storing only the consecutive anomaly centroids\n",
        "for i in anomaly_centroids: \n",
        "    if i not in final_anomaly_centroids: \n",
        "        final_anomaly_centroids.append(i)\n",
        "\n",
        "#Plotting line map to all the consecutive centroids of the anomaly\n",
        "for x in range(0,len(final_anomaly_centroids)-1):\n",
        "    \n",
        "    for y in range(0,1):\n",
        "        \n",
        "        #Plotting the path only if the difference in the displacement is less than 40km\n",
        "        if(  (round((distance.euclidean((int(final_anomaly_centroids[x][y]),int(final_anomaly_centroids[x][y+1])),(int(final_anomaly_centroids[x+1][y]),int(final_anomaly_centroids[x+1][y+1]) ) )),2)*0.7) < 40 ):\n",
        "\n",
        "            img_radar2 = cv.line(img_radar2, (int(final_anomaly_centroids[x][y]), int(final_anomaly_centroids[x][y+1])), (int(final_anomaly_centroids[x+1][y]), int(final_anomaly_centroids[x+1][y+1])),(0,255,0), 2)\n",
        "\n",
        "            img_radar2 = cv.circle(img_radar2, (final_anomaly_centroids[x][y], final_anomaly_centroids[x][y+1]), 3, (0, 0, 0), -5)\n",
        "\n",
        "            img_radar2 = cv.circle(img_radar2, (final_anomaly_centroids[x+1][y], final_anomaly_centroids[x+1][y+1]), 3, (0, 0, 0), -5)\n",
        "        else: print(final_anomaly_centroids[x],'\\n')\n",
        "#Ending the time sequence\n",
        "end = time.time()\n",
        "print(f\"Runtime {end - start} Seconds\")\n",
        "\n",
        "#Displaying the traced anomaly \n",
        "cv2_imshow(img_radar2)\n",
        "# cv.imwrite(r'C:\\Users\\niran\\Desktop\\Radar_Image_Processing\\RadarData\\GIF_Images\\2017\\April\\13th\\Stage8\\TracedAnomaly.jpeg',img_radar2)\n",
        "cv.waitKey(0)\n",
        "\n",
        "#Printing the path to which the plotted image is going to be saved\n",
        "# destination = args[\"folder\"]\n",
        "# print(destination)\n",
        "\n",
        "# \"\"\"Writing the final plotted image to the destination file. It is going to be the same directory from which images are given as input to the algorithm\"\"\"\n",
        "# cv.imwrite(args['folder']+'\\TestResult.jpeg',img_radar2)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xq4SP_6IcLV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTQUmJ1vIbB0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}