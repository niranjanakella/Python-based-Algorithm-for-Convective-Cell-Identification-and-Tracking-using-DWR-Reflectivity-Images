{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TwoImages_ConvectiveCellTracking.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqY0A8nvGSxj",
        "colab_type": "text"
      },
      "source": [
        "#Convective Cell Identification & TRAcking (CITRA) using Doppler Weather Radar Images\n",
        "\n",
        "The cell below installs the Tesseract-OCR model and the Google Drive Mount sequence.\n",
        "\n",
        "**NOTE**: - When the below cell in run, it pops up a link to request access to your google drive. Open that link and grant acces. Then copy the access code and paste it in the mentioned area in the installation sequence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RxvvbyUvdc-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 827
        },
        "outputId": "98e49aa6-aa01-433b-a2ca-4c9e1a93495e"
      },
      "source": [
        "!pip install pytesseract\n",
        "!sudo apt install tesseract-ocr\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytesseract\n",
            "  Downloading https://files.pythonhosted.org/packages/17/4b/4dbd55388225bb6cd243d21f70e77cb3ce061e241257485936324b8e920f/pytesseract-0.3.6.tar.gz\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from pytesseract) (7.0.0)\n",
            "Building wheels for collected packages: pytesseract\n",
            "  Building wheel for pytesseract (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytesseract: filename=pytesseract-0.3.6-py2.py3-none-any.whl size=13629 sha256=8110e4be2aa51f2d74a4beb23e32becae9b386944c730368205ff6b30ecd44e7\n",
            "  Stored in directory: /root/.cache/pip/wheels/ee/71/72/b98430261d849ae631e283dfc7ccb456a3fb2ed2205714b63f\n",
            "Successfully built pytesseract\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.6\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 11 not upgraded.\n",
            "Need to get 4,795 kB of archives.\n",
            "After this operation, 15.8 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-eng all 4.00~git24-0e00fe6-1.2 [1,588 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-osd all 4.00~git24-0e00fe6-1.2 [2,989 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr amd64 4.00~git2288-10f4998a-2 [218 kB]\n",
            "Fetched 4,795 kB in 1s (4,348 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 144676 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_4.00~git24-0e00fe6-1.2_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_4.00~git24-0e00fe6-1.2_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.00~git2288-10f4998a-2_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
            "Setting up tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
            "Setting up tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
            "Setting up tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BL6UyPh7gxa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"Convective Cell Identification and Tracking using Doppler Weather Radar Images\"\"\"\n",
        "\"\"\"by A Niranjan\"\"\"\n",
        "\n",
        "\"\"\"Algorithm for correlation between the convective systems of two consecutive images\"\"\"\n",
        "\n",
        "#Importing the necessary libraries for the project\n",
        "\n",
        "\"\"\"\n",
        "LIBRARY : USE\n",
        "\n",
        "1. cv2: OpenSourced Computer Vision Library for image recognition.\n",
        "2. Numpy: Popular Numerical Python library for various matrix calculations.\n",
        "3. time: Simulation time analysis.\n",
        "4. os: OS file handling.\n",
        "5. pytesseract: An opensource text recognition library for image matrix to string conversions.\n",
        "6. imutils: Image Utilities for basic image processing functions.\n",
        "7. contours: Potential area boundary formations.\n",
        "8. skimage: OpenSource Measure analysis and image recognition Library for segmentation, geometric transformations and color space manipulation.\n",
        "9. argparse: For passing arguments to the algorithm from terminal.\n",
        "10. scipy.spatial: Displacement analysis.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import time,os\n",
        "import pytesseract\n",
        "import imutils \n",
        "from imutils import contours\n",
        "from skimage import measure\n",
        "import argparse\n",
        "from scipy.spatial import distance\n",
        "from google.colab.patches import cv2_imshow\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ygfl81DfGgli",
        "colab_type": "text"
      },
      "source": [
        "##os.chdir('Your_Data_path_from_Google_Drive')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7FrrPei7o6o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Setting the working directory\n",
        "os.chdir('/content')\n",
        "\n",
        "#Setting the path to the tesseract library executable file\n",
        "pytesseract.pytesseract.tesseract_cmd = (\n",
        "    r'/usr/bin/tesseract'\n",
        ")\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8oAKQiaGbDV",
        "colab_type": "text"
      },
      "source": [
        "##Mention the names of the imaged to be processed below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvnTlaRq7qUG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Converting and reading .gif\n",
        "gif1 = cv.VideoCapture('image1_name')\n",
        "ret1,image1 = gif1.read()\n",
        "gif2 = cv.VideoCapture('image2_name')\n",
        "ret2,image2 = gif2.read()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pK6FFgU7zOk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function for Contour formation with respect to Double Strength bar images.\n",
        "def formcontour_Double1(x):\n",
        "    #Initializing Time sequence \n",
        "        start = time.time()\n",
        "\n",
        "        #Decleration of global variables for image-1 perspective analysis in later functions\n",
        "        global dresolution_1, Date_1, Time_1, Area_1, cX1, cY1, approx1\n",
        "        img_main = x\n",
        "\n",
        "        #Cropping the image with respect to Radar Field in the image\n",
        "        img_radar = x[43:700,6:722]\n",
        "\n",
        "        #Convertion of the image into Gray scale and then a blur filter is used to patch the image \n",
        "        gray = cv.cvtColor(img_radar, cv.COLOR_BGR2GRAY)\n",
        "        blurred = cv.GaussianBlur(gray, (11, 11), 0)\n",
        "\n",
        "        #Thresholding the image for potential area identification\n",
        "        thresh = cv.threshold(blurred, 200, 255, cv.THRESH_BINARY)[1]\n",
        "        thresh = cv.erode(thresh, None, iterations=1)\n",
        "        thresh = cv.dilate(thresh, None, iterations=1)\n",
        "\n",
        "        #Connected Component Analysis to find the major patch formations\n",
        "        labels = measure.label(thresh, connectivity = 2, background=0)\n",
        "        mask = np.zeros(thresh.shape, dtype=\"uint8\")\n",
        "\n",
        "        # Loop formation over the unique categories\n",
        "        for label in np.unique(labels):\n",
        "            # If it were the background label then ignore it\n",
        "            if label == 0:\n",
        "                continue\n",
        "\n",
        "            # Construction of the label mask and determining the total number of pixels in the patches \n",
        "            labelMask = np.zeros(thresh.shape, dtype=\"uint8\")\n",
        "            labelMask[labels == label] = 255\n",
        "            numPixels = cv.countNonZero(labelMask)\n",
        "\n",
        "\n",
        "            # Adding the large components to the mask layer if the total number of connected pixels exceed the 150 range\n",
        "            if numPixels > 150:\n",
        "                mask = cv.add(mask, labelMask)\n",
        "\n",
        "        \"\"\"Implementation of the pytesseract library for text recognition and processing, the pytesseract library can \n",
        "        only process images in the RGB Spectrucm, so it is converted from BGR to RGB colour space\"\"\"\n",
        "\n",
        "        Date_1 = pytesseract.image_to_string((cv.cvtColor(img_main[14:39, 3:137],cv.COLOR_BGR2RGB)))\n",
        "        Time_1 = pytesseract.image_to_string(cv.resize((cv.cvtColor(img_main[14:43, 233:333],cv.COLOR_BGR2RGB)),(150,30)))\n",
        "\n",
        "        #In few cases the image needs to be resized for better recognition\n",
        "        #Lattitude and Logitude detection\n",
        "        lat = pytesseract.image_to_string((cv.resize((cv.cvtColor((img_main[20:39,794:848]),cv.COLOR_BGR2RGB)),(69,25))))\n",
        "        long = pytesseract.image_to_string((cv.resize((cv.cvtColor((img_main[22:39,863:925]),cv.COLOR_BGR2RGB)),(310,75))))\n",
        "\n",
        "        #Kilometer per pixel area recognition.\n",
        "        dresolution_1 =float(pytesseract.image_to_string(cv.resize(((cv.cvtColor((image1[83:100,923:960]),cv.COLOR_BGR2RGB))),(150,70))))\n",
        "\n",
        "\n",
        "        #Potential area contour formation for displaying the largest patches of the Convective_System\n",
        "        contours, _=cv.findContours(mask,cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        #Storing all the contour areas in one list\n",
        "        cntArea = [cv.contourArea(c) for c in contours]\n",
        "        for cnt in contours:\n",
        "\n",
        "            #Only the largest contour area is considered for plotting\n",
        "            if(cv.contourArea(cnt) == max(cntArea)):\n",
        "                epsilon = 0.01*cv.arcLength(cnt,True)\n",
        "\n",
        "                #Polygonal Structure approximation\n",
        "                approx1 = cv.approxPolyDP(cnt,epsilon,True)\n",
        "\n",
        "                #Drawing the contour\n",
        "                image = cv.drawContours(img_radar,[approx1],0,(0,0,255),2)\n",
        "\n",
        "                #Total number of pixels enclosed by the contour\n",
        "                TotalPixels = cv.contourArea(cnt)\n",
        "\n",
        "                #Area Calculation with respect to the km/pixel value as the image is in a (xx,xx,3) format the values measured are \n",
        "                #divided with 30 as the colour spectrum of 3 layers is calculated with respect to kilometer squares.\n",
        "                Area_1 = ((TotalPixels/30)*dresolution_1)\n",
        "\n",
        "                #Determining the centroid of the countour\n",
        "                X = cv.moments(cnt)\n",
        "                cX1 = int(X[\"m10\"] / X[\"m00\"])\n",
        "                cY1 = int(X[\"m01\"] / X[\"m00\"])\n",
        "\n",
        "                #Drawing a line perpendicular from the RADAR to the Contour centroid\n",
        "                cv.line(img_radar, (int(363), int(329)), (int(cX1), int(cY1)),(0,255,0), 2)\n",
        "\n",
        "                #Drwing points on the Contour Centroid and the RADAR Origin\n",
        "                cv.circle(img_radar, (cX1, cY1), 3, (0, 0, 0), -5)\n",
        "                cv.circle(img_radar, (363,329),3,(0,0,0),-5)\n",
        "\n",
        "                #Calculating the distance between the Contour Centroid and the RADAR Origin\n",
        "                D = distance.euclidean((363,329),(cX1,cY1))\n",
        "                DistanceFromRadar1 = round(D,2)\n",
        "                print('RADAR 1:') \n",
        "                print('Date : '+ Date_1)\n",
        "                print('Time Stamp : ' + Time_1)\n",
        "                print('Radar Lat&Long: '+lat+\" , \"+long)\n",
        "                print('Distance From Radar:',round(DistanceFromRadar1*dresolution_1,2), 'km',DirectionOfConvective_System(cX1,cY1))        \n",
        "                print(\"Total Area Covered is: \"+str(round(Area_1,2))+\" Km.sq\")\n",
        "\n",
        "                #Ending the time sequence\n",
        "                end = time.time()\n",
        "                print(f\"Runtime {end - start}\")\n",
        "\n",
        "                #Displaying the image\n",
        "                cv2_imshow(image)\n",
        "                return 'Successful'\n",
        "\n",
        "#Function for Radar statistics of double strength bar image-1\n",
        "def getRadarStats_Double1(x):\n",
        "    ContourFormation = formcontour_Double1(x)\n",
        "    if(ContourFormation == 'Successful'):\n",
        "        print('\\nConvective_System Found in 1st Image')\n",
        "        return 'Successful'\n",
        "    else: print('\\nNo Convective_System in 1st Image')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTsU7d0M7zvv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function for Contour formation with respect to Double Strength bar images.\n",
        "def formcontour_Double2(x):\n",
        "    #Initializing Time sequence\n",
        "    start = time.time()\n",
        "    \n",
        "    #Decleration of global variables for image-1 perspective analysis in later functions\n",
        "    global dresolution_2, Date_2, Time_2, Area_2, cX2, cY2,img_radar2\n",
        "    img_main = x\n",
        "    \n",
        "    #Cropping the image with respect to Radar Field in the image\n",
        "    img_radar2 = x[43:700,6:722]\n",
        "    \n",
        "    #Convertion of the image into Gray scale and then a blur filter is used to patch the image \n",
        "    gray = cv.cvtColor(img_radar2, cv.COLOR_BGR2GRAY)\n",
        "    blurred = cv.GaussianBlur(gray, (11, 11), 0)\n",
        "    \n",
        "    #Thresholding the image for potential area identification\n",
        "    thresh = cv.threshold(blurred, 200, 255, cv.THRESH_BINARY)[1]\n",
        "    thresh = cv.erode(thresh, None, iterations=1)\n",
        "    thresh = cv.dilate(thresh, None, iterations=1)\n",
        "    \n",
        "    #Connected Component Analysis to find the major patch formations\n",
        "    labels = measure.label(thresh, connectivity = 2, background=0)\n",
        "    mask = np.zeros(thresh.shape, dtype=\"uint8\")\n",
        "\n",
        "    # Loop formation over the unique categories\n",
        "    for label in np.unique(labels):\n",
        "        \n",
        "        # If it were the background label then ignore it\n",
        "        if label == 0:\n",
        "            continue\n",
        "\n",
        "        # Construction of the label mask and determining the total number of pixels in the patches \n",
        "        labelMask = np.zeros(thresh.shape, dtype=\"uint8\")\n",
        "        labelMask[labels == label] = 255\n",
        "        numPixels = cv.countNonZero(labelMask)\n",
        "\n",
        "\n",
        "\n",
        "        # Adding the large components to the mask layer if the total number of connected pixels exceed the 150 range\n",
        "        if numPixels > 150:\n",
        "            mask = cv.add(mask, labelMask)\n",
        "            \n",
        "    \"\"\"Implementation of the pytesseract library for text recognition and processing, the pytesseract library can \n",
        "    only process images in the RGB Spectrucm, so it is converted from BGR to RGB colour space\"\"\"\n",
        "    \n",
        "    Date_2 = pytesseract.image_to_string((cv.cvtColor(img_main[14:39, 3:137],cv.COLOR_BGR2RGB)))\n",
        "    Time_2 = pytesseract.image_to_string(cv.resize((cv.cvtColor(img_main[14:43, 233:333],cv.COLOR_BGR2RGB)),(150,30)))\n",
        "    \n",
        "    #In few cases the image needs to be resized for better recognition\n",
        "    #Lattitude and Logitude detection\n",
        "    lat = pytesseract.image_to_string((cv.resize((cv.cvtColor((img_main[20:39,794:848]),cv.COLOR_BGR2RGB)),(69,25))))\n",
        "    long = pytesseract.image_to_string((cv.resize((cv.cvtColor((img_main[22:39,863:925]),cv.COLOR_BGR2RGB)),(310,75))))\n",
        "    \n",
        "    #Kilometer per pixel area recognition.\n",
        "    dresolution_2 =float(pytesseract.image_to_string(cv.resize(((cv.cvtColor((image1[83:100,923:960]),cv.COLOR_BGR2RGB))),(150,70))))\n",
        "    \n",
        "    \n",
        "    #Potential area contour formation for displaying the largest patches of the Convective_System\n",
        "    contours, _=cv.findContours(mask,cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
        "    \n",
        "    #Storing all the contour areas in one list\n",
        "    cntArea = [cv.contourArea(c) for c in contours]\n",
        "    for cnt in contours:\n",
        "        \n",
        "        #Only the largest contour area is considered for plotting\n",
        "        if(cv.contourArea(cnt) == max(cntArea)):\n",
        "            epsilon = 0.01*cv.arcLength(cnt,True)\n",
        "            \n",
        "            #Polygonal Structure approximation\n",
        "            approx = cv.approxPolyDP(cnt,epsilon,True)\n",
        "            \n",
        "            #Drawing the contour\n",
        "            img_radar2 = cv.drawContours(img_radar2,[approx],0,(0,0,255),2)\n",
        "            \n",
        "            #Total number of pixels enclosed by the contour\n",
        "            TotalPixels = cv.contourArea(cnt)\n",
        "            \n",
        "            #Area Calculation with respect to the km/pixel value as the image is in a (xx,xx,3) format the values measured are \n",
        "            #divided with 30 as the colour spectrum of 3 layers is calculated with respect to kilometer squares.\n",
        "            Area_2 = ((TotalPixels/30)*dresolution_2)\n",
        "            \n",
        "            #Determining the centroid of the countour\n",
        "            X = cv.moments(cnt)\n",
        "            cX2 = int(X[\"m10\"] / X[\"m00\"])\n",
        "            cY2 = int(X[\"m01\"] / X[\"m00\"])\n",
        "            \n",
        "            #Drawing a line perpendicular from the RADAR to the Contour centroid\n",
        "            img_radar2 = cv.line(img_radar2, (int(363), int(329)), (int(cX2), int(cY2)),(0,255,0), 2)\n",
        "            \n",
        "            #Drwing points on the Contour Centroid and the RADAR Origin\n",
        "            img_radar2 = cv.circle(img_radar2, (cX2, cY2), 3, (0, 0, 0), -5)\n",
        "            img_radar2 = cv.circle(img_radar2, (363,329),3,(0,0,0),-5)\n",
        "            \n",
        "            #Calculating the distance between the Contour Centroid and the RADAR Origin\n",
        "            D = distance.euclidean((363,329),(cX2,cY2))\n",
        "            DistanceFromRadar2 = round(D,2)\n",
        "            \n",
        "            #Printing all the necessary details         \n",
        "            print('RADAR 2:')\n",
        "            print('Date: '+ Date_2)\n",
        "            print('Time Stamp: ' + Time_2)\n",
        "            print('Radar Lat&Long: '+lat+\" , \"+long)\n",
        "            print('Distance From Radar:',round(DistanceFromRadar2*dresolution_2,2), 'km',DirectionOfConvective_System(cX2,cY2))        \n",
        "            print(\"Total Area Covered is: \"+str(round(Area_2,2))+\" Km.sq\")\n",
        "\n",
        "            #Ending the time sequence\n",
        "            end = time.time()\n",
        "            print(f\"Runtime {end - start}\")\n",
        "\n",
        "            #Ending the time sequence\n",
        "            cv2_imshow(img_radar2)\n",
        "            return 'Successful'\n",
        "\n",
        "#Function for Radar statistics of double strength bar image-2\n",
        "def getRadarStats_Double2(x):\n",
        "    ContourFormation = formcontour_Double2(x)\n",
        "    if(ContourFormation == 'Successful'): \n",
        "        print('\\nConvective_System Found in 2nd Image')\n",
        "        return 'Successful'\n",
        "    else: print('\\nNo Convective_System in 2nd Image')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-wSAfhF7zoI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function for Contour formation with respect to Single Strength bar images.\n",
        "def formcontour_Single1(x):\n",
        "    \n",
        "    #Initializing Time sequence \n",
        "    start = time.time()\n",
        "\n",
        "    #Decleration of global variables for image-1 perspective analysis in later functions\n",
        "    global dresolution_1, Date_1, Time_1, Area_1, cX1, cY1, approx1\n",
        "    img_main = x\n",
        "\n",
        "    #Cropping the image with respect to Radar Field in the image\n",
        "    img_radar = x[43:752,6:759]\n",
        "\n",
        "    #Convertion of the image into Gray scale and then a blur filter is used to patch the image \n",
        "    gray = cv.cvtColor(img_radar, cv.COLOR_BGR2GRAY)\n",
        "    blurred = cv.GaussianBlur(gray, (11, 11), 0)\n",
        "\n",
        "    #Thresholding the image for potential area identification\n",
        "    thresh = cv.threshold(blurred, 200, 255, cv.THRESH_BINARY)[1]\n",
        "    thresh = cv.erode(thresh, None, iterations=1)\n",
        "    thresh = cv.dilate(thresh, None, iterations=1)\n",
        "\n",
        "    #Connected Component Analysis to find the major patch formations\n",
        "    labels = measure.label(thresh, connectivity = 2, background=0)\n",
        "    mask = np.zeros(thresh.shape, dtype=\"uint8\")\n",
        "\n",
        "    # Loop formation over the unique categories\n",
        "    for label in np.unique(labels):\n",
        "\n",
        "\n",
        "        # If it were the background label then ignore it\n",
        "        if label == 0:\n",
        "            continue\n",
        "\n",
        "        # If it were the background label then ignore it \n",
        "        labelMask = np.zeros(thresh.shape, dtype=\"uint8\")\n",
        "        labelMask[labels == label] = 255\n",
        "        numPixels = cv.countNonZero(labelMask)\n",
        "\n",
        "\n",
        "        # Adding the large components to the mask layer if the total number of connected pixels exceed the 150 range\n",
        "        if numPixels > 150:\n",
        "            mask = cv.add(mask, labelMask)\n",
        "\n",
        "\n",
        "    \"\"\"Implementation of the pytesseract library for text recognition and processing, the pytesseract library can \n",
        "    only process images in the RGB Spectrucm, so it is converted from BGR to RGB colour space\"\"\"\n",
        "\n",
        "    Date_1 = pytesseract.image_to_string((cv.cvtColor(img_main[14:39, 3:137],cv.COLOR_BGR2RGB)))\n",
        "    Time_1 = pytesseract.image_to_string(cv.resize((cv.cvtColor(img_main[14:43, 233:333],cv.COLOR_BGR2RGB)),(110,30)))\n",
        "\n",
        "    #In few cases the image needs to be resized for better recognition\n",
        "    #Lattitude and Logitude detection\n",
        "    lat = pytesseract.image_to_string((cv.resize((cv.cvtColor((img_main[20:39,794:848]),cv.COLOR_BGR2RGB)),(69,25))))\n",
        "    long = pytesseract.image_to_string((cv.resize((cv.cvtColor((img_main[22:39,863:925]),cv.COLOR_BGR2RGB)),(310,75))))\n",
        "\n",
        "    #Kilometer per pixel area recognition.\n",
        "    dresolution_1 =float(pytesseract.image_to_string(cv.resize(((cv.cvtColor((image1[83:100,923:960]),cv.COLOR_BGR2RGB))),(150,70))))\n",
        "\n",
        "\n",
        "    #Potential area contour formation for displaying the largest patches of the Convective_System\n",
        "    contours, _=cv.findContours(mask,cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    #Storing all the contour areas in one list\n",
        "    cntArea = [cv.contourArea(c) for c in contours]\n",
        "    for cnt in contours:\n",
        "\n",
        "        #Only the largest contour area is considered for plotting\n",
        "        if(cv.contourArea(cnt) == max(cntArea)):\n",
        "            epsilon = 0.01*cv.arcLength(cnt,True)\n",
        "\n",
        "            #Polygonal Structure approximation\n",
        "            approx1 = cv.approxPolyDP(cnt,epsilon,True)\n",
        "\n",
        "            #Drawing the contour\n",
        "            cv.drawContours(img_radar,[approx1],0,(0,0,255),2)\n",
        "\n",
        "            #Total number of pixels enclosed by the contour\n",
        "            TotalPixels = cv.contourArea(cnt)\n",
        "\n",
        "            #Area Calculation with respect to the km/pixel value as the image is in a (xx,xx,3) format the values measured are \n",
        "            #divided with 30 as the colour spectrum of 3 layers is calculated with respect to kilometer squares.\n",
        "            Area_1 = ((TotalPixels/30)*dresolution_1)\n",
        "\n",
        "            #Determining the centroid of the countour\n",
        "            X = cv.moments(cnt)\n",
        "            cX1 = int(X[\"m10\"] / X[\"m00\"])\n",
        "            cY1 = int(X[\"m01\"] / X[\"m00\"])\n",
        "\n",
        "            #Drawing a line perpendicular from the RADAR to the Contour centroid\n",
        "            cv.line(img_radar, (int(376), int(353)), (int(cX1), int(cY1)),(0,255,0), 2)\n",
        "\n",
        "            #Drwing points on the Contour Centroid and the RADAR Origin\n",
        "            cv.circle(img_radar, (cX1, cY1), 3, (0, 0, 0), -5)\n",
        "            cv.circle(img_radar, (376,353),3,(0,0,0),-5)\n",
        "\n",
        "            #Calculating the distance between the Contour Centroid and the RADAR Origin\n",
        "            D = distance.euclidean((363,329),(cX1,cY1))\n",
        "            DistanceFromRadar = round(D,2)\n",
        "\n",
        "\n",
        "            #Printing all the necessary details         \n",
        "            print('RADAR 1:') \n",
        "            print('Date1: '+ Date_1)\n",
        "            print('Time Stamp 1: ' + Time_1)\n",
        "            print('Radar Lat&Long: '+lat+\" , \"+long)\n",
        "            print('Distance From Radar:',round(DistanceFromRadar*dresolution_1,2), 'km',DirectionOfConvective_System(cX1,cY1))        \n",
        "            print(\"Total Area Covered is: \"+str(round(Area_1,2))+\" Km.sq\")\n",
        "\n",
        "            #Ending the time sequence\n",
        "            end = time.time()\n",
        "            print(f\"Runtime {end - start}\")\n",
        "\n",
        "            #Displaying the image\n",
        "            cv2_imshow(img_radar)\n",
        "            return 'Successful'\n",
        "\n",
        "def getRadarStats_Single1(x):\n",
        "    ContourFormation = formcontour_Single1(x)\n",
        "    if(ContourFormation == 'Successful'):\n",
        "        print('\\nConvective_System Found in 1st Image')\n",
        "        return 'Successful'\n",
        "    else: print('\\nNo Convective_System in 1st Image')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVdx-X9M7q3f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function for Contour formation with respect to Single Strength bar images.\n",
        "def formcontour_Single2(x):\n",
        "    #Initializing Time sequence\n",
        "    start = time.time()\n",
        "    \n",
        "    #Decleration of global variables for image-1 perspective analysis in later functions\n",
        "    global dresolution_2, Date_2, Time_2, Area_2, cX2, cY2, img_radar2\n",
        "    img_main = x\n",
        "    \n",
        "    #Decleration of global variables for image-1 perspective analysis in later functions\n",
        "    img_radar2 = x[43:752,6:759]\n",
        "    \n",
        "    #Convertion of the image into Gray scale and then a blur filter is used to patch the image \n",
        "    gray = cv.cvtColor(img_radar2, cv.COLOR_BGR2GRAY)\n",
        "    blurred = cv.GaussianBlur(gray, (11, 11), 0)\n",
        "    \n",
        "    #Thresholding the image for potential area identification\n",
        "    thresh = cv.threshold(blurred, 200, 255, cv.THRESH_BINARY)[1]\n",
        "    thresh = cv.erode(thresh, None, iterations=1)\n",
        "    thresh = cv.dilate(thresh, None, iterations=1)\n",
        "    \n",
        "    #Connected Component Analysis to find the major patch formations\n",
        "    labels = measure.label(thresh, connectivity = 2, background=0)\n",
        "    mask = np.zeros(thresh.shape, dtype=\"uint8\")\n",
        "\n",
        "    # Loop formation over the unique categories\n",
        "    for label in np.unique(labels):\n",
        "        \n",
        "        # If it were the background label then ignore it\n",
        "        if label == 0:\n",
        "            continue\n",
        "\n",
        "        \n",
        "        # Construction of the label mask and determining the total number of pixels in the patches\n",
        "        labelMask = np.zeros(thresh.shape, dtype=\"uint8\")\n",
        "        labelMask[labels == label] = 255\n",
        "        numPixels = cv.countNonZero(labelMask)\n",
        "\n",
        "\n",
        "\n",
        "        # Adding the large components to the mask layer if the total number of connected pixels exceed the 150 range\n",
        "        if numPixels > 150:\n",
        "            mask = cv.add(mask, labelMask)\n",
        "            \n",
        "    \"\"\"Implementation of the pytesseract library for text recognition and processing, the pytesseract library can \n",
        "    only process images in the RGB Spectrucm, so it is converted from BGR to RGB colour space\"\"\"\n",
        "    \n",
        "    Date_2 = pytesseract.image_to_string((cv.cvtColor(img_main[14:39, 3:137],cv.COLOR_BGR2RGB)))\n",
        "    Time_2 = pytesseract.image_to_string(cv.resize((cv.cvtColor(img_main[14:43, 233:333],cv.COLOR_BGR2RGB)),(110,30)))\n",
        "    \n",
        "    #In few cases the image needs to be resized for better recognition\n",
        "    #Lattitude and Logitude detection\n",
        "    lat = pytesseract.image_to_string((cv.resize((cv.cvtColor((img_main[20:39,794:848]),cv.COLOR_BGR2RGB)),(69,25))))\n",
        "    long = pytesseract.image_to_string((cv.resize((cv.cvtColor((img_main[22:39,863:925]),cv.COLOR_BGR2RGB)),(310,75))))\n",
        "    \n",
        "    #Kilometer per pixel area recognition.\n",
        "    dresolution_2 =float(pytesseract.image_to_string(cv.resize(((cv.cvtColor((image1[83:100,923:960]),cv.COLOR_BGR2RGB))),(150,70))))\n",
        "    \n",
        "    #Potential area contour formation for displaying the largest patches of the Convective_System\n",
        "    contours, _=cv.findContours(mask,cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
        "    \n",
        "    #Storing all the contour areas in one list\n",
        "    cntArea = [cv.contourArea(c) for c in contours]\n",
        "    \n",
        "    \n",
        "    for cnt in contours:\n",
        "        \n",
        "        #Only the largest contour area is considered for plotting\n",
        "        if(cv.contourArea(cnt) == max(cntArea)):\n",
        "            epsilon = 0.01*cv.arcLength(cnt,True)\n",
        "            \n",
        "            #Polygonal Structure approximation\n",
        "            approx = cv.approxPolyDP(cnt,epsilon,True)\n",
        "            \n",
        "            #Drawing the contour\n",
        "            img_radar2 = cv.drawContours(img_radar2,[approx],0,(0,0,255),2)\n",
        "            \n",
        "            #Total number of pixels enclosed by the contour\n",
        "            TotalPixels = cv.contourArea(cnt)\n",
        "            \n",
        "            #Area Calculation with respect to the km/pixel value as the image is in a (xx,xx,3) format the values measured are \n",
        "            #divided with 30 as the colour spectrum of 3 layers is calculated with respect to kilometer squares.\n",
        "            Area_2 = ((TotalPixels/30)*dresolution_2)\n",
        "            \n",
        "            #Determining the centroid of the countour\n",
        "            X = cv.moments(cnt)\n",
        "            cX2 = int(X[\"m10\"] / X[\"m00\"])\n",
        "            cY2 = int(X[\"m01\"] / X[\"m00\"])\n",
        "            \n",
        "            #Drawing a line perpendicular from the RADAR to the Contour centroid\n",
        "            img_radar2 = cv.line(img_radar2, (int(376), int(353)), (int(cX2), int(cY2)),(0,255,0), 2)\n",
        "            \n",
        "            #Drwing points on the Contour Centroid and the RADAR Origin\n",
        "            img_radar2 = cv.circle(img_radar2, (cX2, cY2), 3, (0, 0, 0), -5)\n",
        "            img_radar2 = cv.circle(img_radar2, (376,353),3,(0,0,0),-5)\n",
        "            \n",
        "            #Calculating the distance between the Contour Centroid and the RADAR Origin\n",
        "            D = distance.euclidean((363,329),(cX2,cY2))\n",
        "            DistanceFromRadar = round(D,2)\n",
        "            \n",
        "            #Printing all the necessary details  \n",
        "            print('RADAR 2:')\n",
        "            print('Date2: '+ Date_2)\n",
        "            print('Time Stamp 2: ' + Time_2)\n",
        "            print('Radar Lat&Long: '+lat+\" , \"+long)\n",
        "            print('Distance From Radar:',round(DistanceFromRadar*dresolution_2,2), 'km',DirectionOfConvective_System(cX2,cY2))        \n",
        "            print(\"Total Area Covered is: \"+str(round(Area_2,2))+\" Km.sq\")\n",
        "\n",
        "            #Ending the time sequence\n",
        "            end = time.time()\n",
        "            print(f\"Runtime {end - start}\")\n",
        "\n",
        "            #Ending the time sequence\n",
        "            cv2_imshow(img_radar2)\n",
        "            return 'Successful'\n",
        "\n",
        "#Function for Radar statistics of Single strength bar image-2\n",
        "def getRadarStats_Single2(x):\n",
        "    ContourFormation = formcontour_Single2(x)\n",
        "    if(ContourFormation == 'Successful'): \n",
        "        print('\\nConvective_System Found in 2nd Image')\n",
        "        return 'Successful'\n",
        "    else: print('\\nNo Convective_System in 2nd Image')\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJDX1CfP7rV9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"A conditional function to determine the direction of the Convective_System/Potential area\n",
        "i.e, 0 = North; 90 = East; 180 = South; 270 = West; 360 = North\n",
        "for the NE, NW, SE, SW detection, the complete radar area is subdivided into 4 Quadrants and then calculated accordingly.\"\"\"\n",
        "def DirectionOfConvective_System(x,y):\n",
        "    if(x == 363 and y < 329): return 'North'\n",
        "    elif(x >= 358 and x <= 369 and y < 288): return 'North'\n",
        "    elif(x > 369 and y < 329): return 'North East '\n",
        "    elif(x > 363 and y == 329): return 'Easy'\n",
        "    elif(x > 490 and y >= 324 and y <= 334): return 'East'\n",
        "    elif (x > 363 and y > 334): return 'South East'\n",
        "    elif(x == 363 and y > 329): return 'South'\n",
        "    elif(x >= 358 and x <= 369 and y > 500): return 'South'\n",
        "    elif(x < 358 and y > 334): return 'South West'\n",
        "    elif(x < 363 and y == 329): return 'West'\n",
        "    elif(x < 230 and y >= 324 and y <= 334): return 'West'\n",
        "    elif(x < 358 and y < 334): return 'North West'\n",
        "    \n",
        "\"\"\"The pytesseract library converts the image matrix into string values, but for time calculation purpose we use the following\n",
        "function to calculate the total number of seconds by splitting the time string value in to sub divisions as Hours,Mininutes & Seconds\"\"\"\n",
        "def get_sec(time_str):\n",
        "    \n",
        "    #Splitting with respect to collon as the time in string is of the form HH:MM:SS\n",
        "    h, m, s = time_str.split(':')\n",
        "    \n",
        "    #Multiplying the respective values with seconds equivalents and returning from the called function \n",
        "    return int(h) * 3600 + int(m) * 60 + int(s)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLraERV_8FYz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Combined function for RADAR information determination and tracking.\n",
        "#In the following function the conditional statements are used to execute various functions depending on the image dimensions.\n",
        "def FinalRadarStats(image1,image2):\n",
        "    global radar1_info, radar2_info\n",
        "    \n",
        "    if(image1.shape == (770,1078,3)):\n",
        "        radar1_info = getRadarStats_Single1(image1)\n",
        "    elif(image1.shape == (720,1082,3)):\n",
        "        radar1_info = getRadarStats_Double1(image1)\n",
        "    if(image2.shape == (770,1078,3)):\n",
        "        radar2_info = getRadarStats_Single2(image2)\n",
        "    elif(image2.shape == (720,1082,3)):\n",
        "        radar2_info = getRadarStats_Double2(image2)\n",
        "\n",
        "\n",
        "#Calling the combined function for complete RADAR Stats\n",
        "FinalRadarStats(image1,image2)\n",
        "\n",
        "# The following statement will run if the time difference is less than 70minutes, Area difference is less than 20 km.sq \n",
        "    # and displacement less than 100 km\n",
        "\n",
        "if(radar1_info == 'Successful' and radar2_info == 'Successful'):\n",
        "    #Time difference between the two detections in minutes\n",
        "    time_difference = round((abs(get_sec(Time_1)-get_sec(Time_2)))/60,2)\n",
        "\n",
        "    #Area difference between two detections\n",
        "    area_difference = round((abs(Area_1 - Area_2)),2)\n",
        "\n",
        "    #Displacement between two time stamps with respect to the respective centroids\n",
        "    distance_travelled = round((distance.euclidean((cX1,cY1),(cX2,cY2)))*dresolution_2 ,2)\n",
        "\n",
        "\n",
        "    if(time_difference < 70 and area_difference < 40 and distance_travelled < 60):\n",
        "\n",
        "        #Printing the time difference, area difference & the displacement of the convective systems.\n",
        "        print('Time Difference: ', time_difference, 'Minutes')\n",
        "        print('Area Difference: ',area_difference, 'Km.sq')\n",
        "        print('Distance Travelled by Convective_System: ', distance_travelled,'Km')\n",
        "        print('Convective_System TRACKED SUCCESSFULLY!!!!')\n",
        "\n",
        "        #Drawing relationg between consecutive frames\n",
        "        img_radar2 = cv.drawContours(img_radar2,[approx1],0,(0,255,0),2)\n",
        "        img_radar2 = cv.line(img_radar2, (int(cX1), int(cY1)), (int(cX2), int(cY2)),(0,0,0), 2)\n",
        "        img_radar2 = cv.circle(img_radar2, (cX1, cY1), 3, (0, 0, 0), -5)\n",
        "        img_radar2 = cv.circle(img_radar2, (cX2, cY2), 3, (0, 0, 0), -5)\n",
        "        cv2_imshow(img_radar2)\n",
        "    else: print(\"\\nConvective_System Couldn't be traced\")\n",
        "        \n",
        "else: print('\\nConvective_System Not Traced')\n",
        "\n",
        "#Displaying the Convective_System\n",
        "cv.waitKey(0)\n",
        "\n",
        "#The following command can be uncommented to save the final image to the required destination\n",
        "# cv.imwrite('Destination_Path',img_radar2)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}